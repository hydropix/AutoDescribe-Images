"""OpenRouter API client with vision model support."""

import base64
import logging
import time
from pathlib import Path

import requests

logger = logging.getLogger(__name__)

# OpenRouter API endpoint
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Session cost tracking
_session_cost = 0.0
_session_tokens = {"prompt": 0, "completion": 0}


def get_session_cost() -> tuple[float, dict[str, int]]:
    """Get the current session cost and token usage.

    Returns:
        Tuple of (total_cost_usd, token_counts_dict)
    """
    return _session_cost, _session_tokens.copy()


def reset_session_cost() -> None:
    """Reset the session cost tracking."""
    global _session_cost, _session_tokens
    _session_cost = 0.0
    _session_tokens = {"prompt": 0, "completion": 0}

# Fallback vision models (sorted by cost, cheapest first)
OPENROUTER_VISION_MODELS_FALLBACK = [
    # === CHEAP MODELS ===
    "google/gemini-2.0-flash-001",
    "google/gemini-2.5-flash-preview",
    "meta-llama/llama-3.2-11b-vision-instruct",
    "qwen/qwen2.5-vl-32b-instruct",
    "openai/gpt-4o-mini",
    "qwen/qwen2.5-vl-72b-instruct",
    "meta-llama/llama-3.2-90b-vision-instruct",
    # === PREMIUM MODELS ===
    "google/gemini-pro-vision",
    "qwen/qwen-vl-max",
    "anthropic/claude-3.5-sonnet",
    "anthropic/claude-sonnet-4",
    "openai/gpt-4o",
]


def get_mime_type(file_path: Path) -> str:
    """Get MIME type based on file extension."""
    ext = file_path.suffix.lower()
    mime_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp',
        '.bmp': 'image/bmp'
    }
    return mime_types.get(ext, 'image/jpeg')


def encode_image_base64(image_path: Path) -> str:
    """Encode an image to base64.

    Args:
        image_path: Path to the image.

    Returns:
        The base64 encoded image.
    """
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def describe_image(
    image_path: Path,
    model: str,
    system_prompt: str,
    api_key: str,
    temperature: float = 0.7,
    max_tokens: int = 500,
) -> str:
    """Generate a description of an image via OpenRouter.

    Args:
        image_path: Path to the image to describe.
        model: Name of the OpenRouter model to use.
        system_prompt: System prompt to guide the description.
        api_key: OpenRouter API key.
        temperature: Temperature for generation.
        max_tokens: Maximum tokens in response.

    Returns:
        The description generated by the model.

    Raises:
        requests.exceptions.RequestException: On API error.
        ValueError: On invalid response.
    """
    logger.debug(f"Encoding image: {image_path.name}")
    encode_start = time.time()

    image_data = encode_image_base64(image_path)
    mime_type = get_mime_type(image_path)
    encode_time = time.time() - encode_start
    logger.debug(f"Image encoded in {encode_time:.2f}s - {len(image_data)} bytes base64")

    # Prepare request
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "HTTP-Referer": "https://github.com/hydropix/AutoDescribe-Images",
        "X-Title": "AutoDescribe-Images",
    }

    data = {
        "model": model,
        "messages": [
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": system_prompt + "\n\nDescribe this image."
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{image_data}"
                        }
                    }
                ]
            }
        ],
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    logger.info(f"Sending request to OpenRouter model '{model}' for: {image_path.name}")
    api_start = time.time()

    response = requests.post(OPENROUTER_API_URL, headers=headers, json=data, timeout=120)
    response.raise_for_status()

    result = response.json()
    api_time = time.time() - api_start

    if 'choices' not in result or len(result['choices']) == 0:
        raise ValueError(f"Unexpected response format: {result}")

    response_content = result['choices'][0]['message']['content']

    # Track cost from usage data
    global _session_cost, _session_tokens
    usage = result.get("usage", {})
    prompt_tokens = usage.get("prompt_tokens", 0)
    completion_tokens = usage.get("completion_tokens", 0)

    # OpenRouter returns cost in the response (in USD)
    # If not available, estimate from token counts (rough estimate)
    if "cost" in result:
        cost = float(result.get("cost", 0))
    else:
        # Fallback: estimate cost (Gemini Flash rates as default)
        # $0.10/M input, $0.40/M output
        cost = (prompt_tokens * 0.10 / 1_000_000) + (completion_tokens * 0.40 / 1_000_000)

    _session_cost += cost
    _session_tokens["prompt"] += prompt_tokens
    _session_tokens["completion"] += completion_tokens

    logger.info(
        f"Response received in {api_time:.2f}s (length: {len(response_content)} chars) | "
        f"Tokens: {prompt_tokens}+{completion_tokens} | Cost: ${cost:.6f} (session: ${_session_cost:.4f})"
    )
    logger.debug(f"Response preview: {response_content[:100]}...")

    return response_content


def list_openrouter_models(api_key: str | None = None) -> list[str]:
    """List available OpenRouter vision models, sorted by price (cheapest first).

    Args:
        api_key: OpenRouter API key (optional, uses default list if not provided).

    Returns:
        List of model names sorted by price (free models first, then by cost).
    """
    if not api_key:
        return OPENROUTER_VISION_MODELS_FALLBACK

    try:
        headers = {
            "Authorization": f"Bearer {api_key}",
        }
        response = requests.get(
            "https://openrouter.ai/api/v1/models",
            headers=headers,
            timeout=10
        )
        response.raise_for_status()

        models = response.json().get("data", [])
        # Filter for vision-capable models (those that support images)
        vision_models = []
        for model in models:
            model_id = model.get("id", "")
            # Include models known to support vision or with vision in architecture
            architecture = model.get("architecture", {})
            if architecture.get("modality") == "multimodal" or "vision" in model_id.lower():
                # Get pricing info (price per token)
                pricing = model.get("pricing", {})
                # Use prompt price as main cost indicator
                prompt_price = float(pricing.get("prompt", "999") or "999")
                completion_price = float(pricing.get("completion", "999") or "999")
                total_price = prompt_price + completion_price
                vision_models.append((model_id, total_price))

        # If filtering didn't work well, return fallback
        if len(vision_models) < 5:
            return OPENROUTER_VISION_MODELS_FALLBACK

        # Sort by price (cheapest first, free models at top)
        vision_models.sort(key=lambda x: x[1])

        # Return just the model names
        return [model_id for model_id, _ in vision_models]

    except Exception as e:
        logger.warning(f"Failed to fetch OpenRouter models: {e}")
        return OPENROUTER_VISION_MODELS_FALLBACK
