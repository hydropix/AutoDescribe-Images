# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=qwen3-vl:4b

# OpenRouter Configuration (optional, for cloud-based vision models)
# Get your API key from https://openrouter.ai/keys
OPENROUTER_API_KEY=
